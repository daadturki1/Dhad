{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_psjzSt9ffP2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import sys\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from pathlib import Path\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from tensorflow.python import metrics\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential, Model\n",
        "from sklearn import svm\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.ops.metrics import accuracy\n",
        "import numpy\n",
        "import sklearn.metrics as metrics\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
        "from sklearn.svm import SVC\n",
        "import docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYAD-3Ewfkhg"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"Dhad-Split.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "870IYF6pfnmh"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator (\n",
        "    rescale = 1./255.,\n",
        ")\n",
        "training_set = train_datagen.flow_from_directory (\n",
        "    \"/content/Dhad-Split/train\",\n",
        "    target_size=(32,32),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# extract X and Y\n",
        "training_set.reset()\n",
        "X_train, y_train = next(training_set)\n",
        "for i in tqdm.tqdm(range(int(training_set.n/32)-1)): \n",
        "  img, label = next(training_set)\n",
        "  X_train = np.append(X_train, img, axis=0 )\n",
        "  y_train = np.append(y_train, label, axis=0)\n",
        "print(X_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Uhypqu2fuNF"
      },
      "outputs": [],
      "source": [
        "val_datagen = ImageDataGenerator (\n",
        "    rescale=1./255,\n",
        ")\n",
        "validation_set = val_datagen.flow_from_directory (\n",
        "    \"/content/Dhad-Split/val\",\n",
        "    target_size=(32,32),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# extract X and Y\n",
        "validation_set.reset()\n",
        "X_val, y_val = next(validation_set)\n",
        "for i in tqdm.tqdm(range(int(validation_set.n/32)-1)): \n",
        "  img, label = next(validation_set)\n",
        "  X_val = np.append(X_val, img, axis=0 )\n",
        "  y_val = np.append(y_val, label, axis=0)\n",
        "print(X_val.shape, y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k64e1-P7fwkn"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator (\n",
        "    rescale=1./255,\n",
        ")\n",
        "testing_set = test_datagen.flow_from_directory (\n",
        "    \"/content/Dhad-Split/test\",\n",
        "    target_size=(32,32),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\",\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# extract X and Y\n",
        "testing_set.reset()\n",
        "X_test, y_test = next(testing_set)\n",
        "for i in tqdm.tqdm(range(int(testing_set.n/32)-1)): \n",
        "  img, label = next(testing_set)\n",
        "  X_test = np.append(X_test, img, axis=0 )\n",
        "  y_test = np.append(y_test, label, axis=0)\n",
        "print(X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCYSbLGUfz-f"
      },
      "outputs": [],
      "source": [
        "cnn = load_model('/content/drive/MyDrive/Colab Notebooks/EXP4-Arch2/CNN-Dhad.h5')\n",
        "\n",
        "cnn.pop() # this will remove the last layer\n",
        "cnn.summary() # check the network "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVw2Hrgyf3ra"
      },
      "outputs": [],
      "source": [
        "model_feat = Model(inputs=cnn.input,outputs=cnn.get_layer('dense_7').output)\n",
        "\n",
        "feat_train = model_feat.predict(X_train)\n",
        "print(feat_train.shape)\n",
        "\n",
        "feat_val = model_feat.predict(X_val)\n",
        "print(feat_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feat_test = model_feat.predict(X_test)\n",
        "print(feat_test.shape)"
      ],
      "metadata": {
        "id": "Iv_XMoKBJGU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvDQTfzkf6IQ"
      },
      "outputs": [],
      "source": [
        "svm = SVC(kernel='rbf', C=3, gamma=0.001)\n",
        "svm.fit(feat_train,np.argmax(y_train,axis=1))\n",
        "\n",
        "print('fitting done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi_tcrRDgAB2"
      },
      "outputs": [],
      "source": [
        "round(svm.score(feat_val,np.argmax(y_val,axis=1)),4) *100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7n7kW6WojBK"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# now you can save it to a file\n",
        "filename = '/content/drive/MyDrive/Colab Notebooks/EXP4-CNN-SVM/CNN-SVM-Dhad.pkl'\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(svm, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmdkTPalpGbU"
      },
      "outputs": [],
      "source": [
        "# # and later you can load it\n",
        "# filename = '/content/drive/MyDrive/Colab Notebooks/EXP4-CNN-SVM/CNN-SVM-Hijjaa.pkl'\n",
        "# with open(filename, 'rb') as f:\n",
        "#   svm = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define variables \n",
        "predictions = svm.predict(feat_test)\n",
        "class_labels = list(testing_set.class_indices.keys())  \n",
        "\n",
        "# confusion matrix \n",
        "confusion_matrix = metrics.confusion_matrix(np.argmax(y_test,axis=1), predictions)\n",
        "\n",
        "# FP, FN, TP, TN\n",
        "FP = confusion_matrix.sum(axis=0) - numpy.diag(confusion_matrix)  \n",
        "FN = confusion_matrix.sum(axis=1) - numpy.diag(confusion_matrix)\n",
        "TP = numpy.diag(confusion_matrix)\n",
        "TN = confusion_matrix.sum() - (FP + FN + TP)\n",
        "\n",
        "# Sensitivity, hit rate, recall, or true positive rate\n",
        "TPR = TP/(TP+FN)\n",
        "# Specificity or true negative rate\n",
        "TNR = TN/(TN+FP) \n",
        "# Precision or positive predictive value\n",
        "PPV = TP/(TP+FP)\n",
        "# Negative predictive value\n",
        "NPV = TN/(TN+FN)\n",
        "# Fall out or false positive rate\n",
        "FPR = FP/(FP+TN)\n",
        "# False negative rate\n",
        "FNR = FN/(TP+FN)\n",
        "# False discovery rate\n",
        "FDR = FP/(TP+FP)\n",
        "# F1-Score\n",
        "F1 = 2 * ((PPV*TPR)/(PPV+TPR))\n",
        "\n",
        "# Overall accuracy\n",
        "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "per_class = confusion_matrix.diagonal()/confusion_matrix.sum(axis=0)\n",
        "\n",
        "m_precision = precision_score(np.argmax(y_test,axis=1), predictions, average='macro')\n",
        "m_recall = recall_score(np.argmax(y_test,axis=1), predictions, average='macro')\n",
        "m_f1score = f1_score(np.argmax(y_test,axis=1), predictions, average='macro')\n",
        "\n",
        "w_accuracy = accuracy_score(np.argmax(y_test,axis=1), predictions)\n",
        "w_precision = precision_score(np.argmax(y_test,axis=1), predictions, average='weighted')\n",
        "w_recall = recall_score(np.argmax(y_test,axis=1), predictions, average='weighted')\n",
        "w_f1score = f1_score(np.argmax(y_test,axis=1), predictions, average='weighted')\n",
        "\n",
        "report = {\n",
        "    'Character': class_labels,\n",
        "    'Precision':numpy.round(PPV,4) * 100 ,\n",
        "    'Recall': numpy.round(TPR,4) * 100,\n",
        "    'F1-Score': numpy.round(F1,4) * 100\n",
        "    }\n",
        "df = pd.DataFrame(report)\n",
        "print(df)\n",
        "print()\n",
        "\n",
        "avg = {\n",
        "    ' ': ['Macro Average', 'Weighted Average'],\n",
        "    'Precision': [numpy.round(m_precision,4) * 100, numpy.round(w_precision,4) * 100],\n",
        "    'Recall': [numpy.round(m_recall,4) *100, numpy.round(w_recall,4) * 100],\n",
        "    'F1-Score': [numpy.round(m_f1score,4) * 100, numpy.round(w_f1score,4) * 100],\n",
        "    'Accuracy': ['', numpy.round(w_accuracy,4) * 100]\n",
        "}\n",
        "dfa = pd.DataFrame(avg)\n",
        "print(dfa)"
      ],
      "metadata": {
        "id": "xrITMfLx2cUH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}